{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "\n",
    "data_url=\"https://raw.githubusercontent.com/liraop/recinfo_lab2/master/data/results.csv\"\n",
    "data = pd.read_csv(data_url).replace(np.nan, '', regex=True)\n",
    "documents = data.text.count()\n",
    "items = []\n",
    "\n",
    "def parse(text):\n",
    "    words = []\n",
    "    word_pattern = rpt(r'\\w+')\n",
    "    year_pattern = rpt(r'\\d{4}')\n",
    "    \n",
    "    patterns = [word_pattern, year_pattern]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(text):\n",
    "            if token not in stopwords and len(token) > 3:\n",
    "                tokens.append(token)\n",
    "        words.extend(tokens)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Execute o algoritmo ilustrado na Fig. 5.8 do livro texto (pag. 157) para gerar um índice similar o mostrado na Fig. 5.4 (pag. 134). Guarde o índice em disco em formato csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(dataset):\n",
    "    document_index = 0\n",
    "    index = {\"doc_row\": []}\n",
    "    \n",
    "    for entry in dataset.text:\n",
    "        document_index = document_index + 1\n",
    "        index[\"doc_row\"].append(document_index)\n",
    "            \n",
    "        for ngram in parse(entry):\n",
    "                if ngram in index: #is ngram already on index?\n",
    "                    if document_index in index[ngram]: # is it in the same document?\n",
    "                        index[ngram][document_index] = index[ngram][document_index] + 1\n",
    "                    else: # nope\n",
    "                        index[ngram][document_index] = 1 \n",
    "                else: # no, sir\n",
    "                    index[ngram] = {document_index: 1}\n",
    "    \n",
    "    return index\n",
    "\n",
    "index = build_index(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implemente as abordagens de processamento de consulta documento-por-vez e termo-por-vez (Fig. 5.16 e 5.18). \n",
    "+ Defina 5 consultas de um termo somente. \n",
    "+ Execute as 5 consultas em cada algoritmo retornando os top-10 documentos (parâmetro k do algoritmo).\n",
    "+ Dê evidências de que sua implementação está correta.\n",
    "+ Compare os tempos médios de execução e uso de memória de cada algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def document_at_a_time(query, index, k):\n",
    "    rank = {}\n",
    "    inverted_lists = []\n",
    "    #query as space separated string list\n",
    "    for ngram in query.split(): \n",
    "        if ngram in index:\n",
    "            inverted_lists.append(index[ngram])\n",
    "            \n",
    "    for document_id in index['doc_row']:\n",
    "        rank[document_id] = 0\n",
    "        for i_list in inverted_lists:\n",
    "            for il_doc_id, il_doc_wc in i_list.items():\n",
    "                if il_doc_id == document_id:\n",
    "                    rank[document_id] = rank[document_id] + il_doc_wc\n",
    "                     \n",
    "    return heapq.nlargest(k, rank, rank.get)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explico aqui o codigo acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_at_a_time(query, index, k):\n",
    "    rank = {}\n",
    "    inverted_lists = []\n",
    "    #query as space separated string list\n",
    "    for ngram in query.split(): \n",
    "        if ngram in index:\n",
    "            inverted_lists.append(index[ngram])\n",
    "    \n",
    "    for i_list in inverted_lists:\n",
    "        for il_doc_id, il_doc_wc in i_list.items():\n",
    "            if il_doc_id not in rank:\n",
    "                rank[il_doc_id] = il_doc_wc\n",
    "            else:\n",
    "                rank[il_doc_id] = rank[il_doc_id] + il_doc_wc\n",
    "    \n",
    "    return heapq.nlargest(k, rank, rank.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explico aqui o codigo acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implemente uma das versões de consulta conjuntiva (AND) (Fig. 5.20 ou 5.21).\n",
    "+ Defina 5 consultas conjuntivas (AND).\n",
    "+ Execute as 5 consultas em cada algoritmo retornando os top-10 documentos(parâmetro k do algoritmo).\n",
    "+ Dê evidências de que sua implementação está correta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
