{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "\n",
    "data_url=\"https://raw.githubusercontent.com/liraop/recinfo_lab2/master/data/results.csv\"\n",
    "data = pd.read_csv(data_url).replace(np.nan, '', regex=True)\n",
    "documents = data.text.count()\n",
    "items = []\n",
    "words = []\n",
    "\n",
    "word_token = rpt(r'\\w+')\n",
    "year_token = rpt(r'\\d{4}')\n",
    "\n",
    "def tokenize_it(dataset, pattern, words):\n",
    "    for entry in dataset.text:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(entry):\n",
    "            if token not in stopwords and len(token) > 3:\n",
    "                tokens.append(token)\n",
    "        words.extend(tokens)\n",
    "\n",
    "tokenize_it(dados, word_token, itens)\n",
    "tokenize_it(dados, year_token, itens)\n",
    "\n",
    "df = pd.DataFrame(itens, columns=['palavra'])\n",
    "itens_df = df.palavra.value_counts().reset_index()\n",
    "itens_df.columns = ['palavra', 'frequencia']\n",
    "itens_df['r'] = itens_df.frequencia.rank(ascending=False, method='first')\n",
    "\n",
    "total_itens = len(itens)\n",
    "vocabulary = set(itens)\n",
    "        \n",
    "I = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Execute o algoritmo ilustrado na Fig. 5.8 do livro texto (pag. 157) para gerar um índice similar o mostrado na Fig. 5.4 (pag. 134). Guarde o índice em disco em formato csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(index, dataset):\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implemente as abordagens de processamento de consulta documento-por-vez e termo-por-vez (Fig. 5.16 e 5.18). \n",
    "+ Defina 5 consultas de um termo somente. \n",
    "+ Execute as 5 consultas em cada algoritmo retornando os top-10 documentos (parâmetro k do algoritmo).\n",
    "+ Dê evidências de que sua implementação está correta.\n",
    "+ Compare os tempos médios de execução e uso de memória de cada algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implemente uma das versões de consulta conjuntiva (AND) (Fig. 5.20 ou 5.21).\n",
    "+ Defina 5 consultas conjuntivas (AND).\n",
    "+ Execute as 5 consultas em cada algoritmo retornando os top-10 documentos(parâmetro k do algoritmo).\n",
    "+ Dê evidências de que sua implementação está correta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
